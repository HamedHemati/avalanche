<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>avalanche.training.plugins.cope &mdash; Avalanche 0.1 documentation</title>
      <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/mystyle.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../../search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../">
            <img src="../../../../../_static/avalanche_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Avalanche API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../autoapi/">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../autoapi/avalanche/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../autoapi/avalanche/#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/evaluation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../autoapi/avalanche/#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/core/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.core</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../autoapi/avalanche/#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../autoapi/avalanche/#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../">Avalanche</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../../">Module code</a> &raquo;</li>
      <li>avalanche.training.plugins.cope</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for avalanche.training.plugins.cope</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.nn.functional</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="kn">from</span> <span class="nn">torch.nn.modules</span> <span class="kn">import</span> <span class="n">Module</span>

<span class="kn">from</span> <span class="nn">avalanche.training.utils</span> <span class="kn">import</span> <span class="n">get_last_fc_layer</span><span class="p">,</span> <span class="n">swap_last_fc_layer</span>
<span class="kn">from</span> <span class="nn">avalanche.benchmarks.utils</span> <span class="kn">import</span> <span class="n">AvalancheConcatDataset</span>
<span class="kn">from</span> <span class="nn">avalanche.training.plugins.strategy_plugin</span> <span class="kn">import</span> <span class="n">StrategyPlugin</span>
<span class="kn">from</span> <span class="nn">avalanche.training.storage_policy</span> <span class="kn">import</span> <span class="n">ClassBalancedBuffer</span>
<span class="kn">from</span> <span class="nn">avalanche.benchmarks.utils.data_loader</span> <span class="kn">import</span> \
    <span class="n">ReplayDataLoader</span>


<div class="viewcode-block" id="CoPEPlugin"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin">[docs]</a><span class="k">class</span> <span class="nc">CoPEPlugin</span><span class="p">(</span><span class="n">StrategyPlugin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Continual Prototype Evolution plugin.</span>
<span class="sd">    Each class has a prototype for nearest-neighbor classification.</span>
<span class="sd">    The prototypes are updated continually with an exponentially moving average,</span>
<span class="sd">    using class-balanced replay to keep the prototypes up-to-date.</span>
<span class="sd">    The embedding space is optimized using the PseudoPrototypicalProxy-loss,</span>
<span class="sd">    exploiting both prototypes and batch information.</span>

<span class="sd">    This plugin doesn&#39;t use task identities in training or eval</span>
<span class="sd">    (data incremental) and is designed for online learning (1 epoch per task).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mem_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">p_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
                 <span class="n">T</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_it_cnt</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param mem_size: max number of input samples in the replay memory.</span>
<span class="sd">        :param n_classes: total number of classes that will be encountered. This</span>
<span class="sd">        is used to output predictions for all classes, with zero probability</span>
<span class="sd">        for unseen classes.</span>
<span class="sd">        :param p_size: The prototype size, which equals the feature size of the</span>
<span class="sd">        last layer.</span>
<span class="sd">        :param alpha: The momentum for the exponentially moving average of the</span>
<span class="sd">        prototypes.</span>
<span class="sd">        :param T: The softmax temperature, used as a concentration parameter.</span>
<span class="sd">        :param max_it_cnt: How many processing iterations per batch (experience)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">n_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">it_cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_it_cnt</span> <span class="o">=</span> <span class="n">max_it_cnt</span>

        <span class="c1"># Operational memory: replay memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_mem</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mem_size</span> <span class="o">=</span> <span class="n">mem_size</span>  <span class="c1"># replay memory size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_policy</span> <span class="o">=</span> <span class="n">ClassBalancedBuffer</span><span class="p">(</span>
            <span class="n">max_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mem_size</span><span class="p">,</span>
            <span class="n">adaptive_size</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Operational memory: Prototypical memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Scales with nb classes * feature size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_size</span> <span class="o">=</span> <span class="n">p_size</span>  <span class="c1"># Prototype size determined on runtime</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tmp_p_mem</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Intermediate to process batch for multiple times</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_init_adaptive</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Only create proto when class seen</span>

        <span class="c1"># PPP-loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ppp_loss</span> <span class="o">=</span> <span class="n">PPPloss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="CoPEPlugin.before_training"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin.before_training">[docs]</a>    <span class="k">def</span> <span class="nf">before_training</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Enforce using the PPP-loss and add a NN-classifier.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
            <span class="n">strategy</span><span class="o">.</span><span class="n">_criterion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ppp_loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using the Pseudo-Prototypical-Proxy loss for CoPE.&quot;</span><span class="p">)</span>

            <span class="c1"># Normalize representation of last layer</span>
            <span class="n">swap_last_fc_layer</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                               <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                                   <span class="n">get_last_fc_layer</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span>
                                   <span class="n">L2Normalization</span><span class="p">())</span>
                               <span class="p">)</span>

            <span class="c1"># Static prototype init</span>
            <span class="c1"># Create prototypes for all classes at once</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_init_adaptive</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_init_new_prototypes</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="CoPEPlugin.before_training_exp"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin.before_training_exp">[docs]</a>    <span class="k">def</span> <span class="nf">before_training_exp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Random retrieval from a class-balanced memory.</span>
<span class="sd">        Dataloader builds batches containing examples from both memories and</span>
<span class="sd">        the training dataset.</span>
<span class="sd">        This implementation requires the use of early stopping, otherwise the</span>
<span class="sd">        entire memory will be iterated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_mem</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">it_cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">strategy</span><span class="o">.</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">ReplayDataLoader</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">.</span><span class="n">adapted_dataset</span><span class="p">,</span>
            <span class="n">AvalancheConcatDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_mem</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
            <span class="n">oversample_small_tasks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">strategy</span><span class="o">.</span><span class="n">train_mb_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">force_data_batch_size</span><span class="o">=</span><span class="n">strategy</span><span class="o">.</span><span class="n">train_mb_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span></div>

<div class="viewcode-block" id="CoPEPlugin.after_training_iteration"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin.after_training_iteration">[docs]</a>    <span class="k">def</span> <span class="nf">after_training_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implements early stopping, determining how many subsequent times a</span>
<span class="sd">        batch can be used for updates. The dataloader contains only data for</span>
<span class="sd">        the current experience (batch) and the entire memory.</span>
<span class="sd">        Multiple iterations will hence result in the original batch with new</span>
<span class="sd">        exemplars sampled from the memory for each iteration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">it_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">it_cnt</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_it_cnt</span><span class="p">:</span>
            <span class="n">strategy</span><span class="o">.</span><span class="n">stop_training</span><span class="p">()</span>  <span class="c1"># Stop processing the new-data batch</span></div>

<div class="viewcode-block" id="CoPEPlugin.after_forward"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin.after_forward">[docs]</a>    <span class="k">def</span> <span class="nf">after_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        After the forward we can use the representations to update our running</span>
<span class="sd">        avg of the prototypes. This is in case we do multiple iterations of</span>
<span class="sd">        processing on the same batch.</span>

<span class="sd">        New prototypes are initialized for previously unseen classes.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_init_adaptive</span><span class="p">:</span>  <span class="c1"># Init prototypes for unseen classes in batch</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_new_prototypes</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">mb_y</span><span class="p">)</span>

        <span class="c1"># Update batch info (when multiple iterations on same batch)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_running_prototypes</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span></div>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_init_new_prototypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize prototypes for previously unseen classes.</span>
<span class="sd">        :param targets: The targets Tensor to make prototypes for.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_unique</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_unique</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">y_unique</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">c</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">:</span>  <span class="c1"># Init new prototype</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_size</span><span class="p">))</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_update_running_prototypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Accumulate seen outputs of the network and keep counts. &quot;&quot;&quot;</span>
        <span class="n">y_unique</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">mb_y</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_unique</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">y_unique</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">mb_y</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">p_tmp_batch</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">mb_output</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">strategy</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">p_init</span><span class="p">,</span> <span class="n">cnt_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tmp_p_mem</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> \
                <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tmp_p_mem</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tmp_p_mem</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_init</span> <span class="o">+</span> <span class="n">p_tmp_batch</span><span class="p">,</span> <span class="n">cnt_init</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">idxs</span><span class="p">))</span>

<div class="viewcode-block" id="CoPEPlugin.after_training_exp"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin.after_training_exp">[docs]</a>    <span class="k">def</span> <span class="nf">after_training_exp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; After the current experience (batch), update prototypes and</span>
<span class="sd">        store observed samples for replay.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_prototypes</span><span class="p">()</span>  <span class="c1"># Update prototypes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_policy</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>  <span class="c1"># Update memory</span></div>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_update_prototypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Update the prototypes based on the running averages. &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="n">p_sum</span><span class="p">,</span> <span class="n">p_cnt</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tmp_p_mem</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">incr_p</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">p_sum</span> <span class="o">/</span> <span class="n">p_cnt</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># L2 normalized</span>
            <span class="n">old_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">new_p_momentum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">old_p</span> <span class="o">+</span> <span class="p">(</span>
                    <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">incr_p</span>  <span class="c1"># Momentum update</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">new_p_momentum</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tmp_p_mem</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="CoPEPlugin.after_eval_iteration"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.CoPEPlugin.after_eval_iteration">[docs]</a>    <span class="k">def</span> <span class="nf">after_eval_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert output scores to probabilities for other metrics like</span>
<span class="sd">        accuracy and forgetting. We only do it at this point because before</span>
<span class="sd">        this,we still need the embedding outputs to obtain the PPP-loss.&quot;&quot;&quot;</span>
        <span class="n">strategy</span><span class="o">.</span><span class="n">mb_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_nearest_neigbor_distr</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">mb_output</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_get_nearest_neigbor_distr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find closest prototype for output samples in batch x.</span>
<span class="sd">        :param x: Batch of network logits.</span>
<span class="sd">        :return: one-hot representation of the predicted class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ns</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">nd</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Get prototypes</span>
        <span class="n">seen_c</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">seen_c</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># no prototypes yet, output uniform distr. all classes</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span>
                                <span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">seen_c</span><span class="p">,</span> <span class="n">nd</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">c_proto</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">means</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_proto</span>  <span class="c1"># Class idx gets allocated its prototype</span>

        <span class="c1"># Predict nearest mean</span>
        <span class="n">classpred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ns</span><span class="p">):</span>  <span class="c1"># Per sample</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># Dot product</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ii</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Min dist (no proto = inf)</span>
            <span class="n">ii</span> <span class="o">=</span> <span class="n">ii</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">classpred</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">ii</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># Allocate class idx</span>

        <span class="c1"># Convert to 1-hot</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ns</span><span class="p">):</span>
            <span class="n">out</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">classpred</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">out</span>  <span class="c1"># return 1-of-C code, ns x nc</span></div>


<div class="viewcode-block" id="L2Normalization"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/cope/#avalanche.training.plugins.cope.L2Normalization">[docs]</a><span class="k">class</span> <span class="nc">L2Normalization</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Module to L2-normalize the input. Typically used in last layer to</span>
<span class="sd">    normalize the embedding.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="L2Normalization.forward"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/cope/#avalanche.training.plugins.cope.L2Normalization.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="PPPloss"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.PPPloss">[docs]</a><span class="k">class</span> <span class="nc">PPPloss</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Pseudo-Prototypical Proxy loss (PPP-loss).</span>
<span class="sd">        This is a contrastive loss using prototypes and representations of the</span>
<span class="sd">        samples in the batch to optimize the embedding space.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_mem</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param p_mem: dictionary with keys the prototype identifier and</span>
<span class="sd">                      values the prototype tensors.</span>
<span class="sd">        :param T: temperature of the softmax, serving as concentration</span>
<span class="sd">                  density parameter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span> <span class="o">=</span> <span class="n">p_mem</span>

<div class="viewcode-block" id="PPPloss.__call__"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.PPPloss.__call__">[docs]</a>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The loss is calculated with one-vs-rest batches Bc and Bk,</span>
<span class="sd">        split into the attractor and repellor loss terms.</span>
<span class="sd">        We iterate over the possible batches while accumulating the losses per</span>
<span class="sd">        class c vs other-classes k.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Batch x feature size</span>
        <span class="n">y_unique</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">include_repellor</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_unique</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="mi">1</span>  <span class="c1"># When at least 2 classes</span>

        <span class="c1"># All prototypes</span>
        <span class="n">p_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="o">.</span><span class="n">keys</span><span class="p">()])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">p_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">p_mem</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">p_y</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">label_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_unique</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>  <span class="c1"># Per-class operation</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">y_unique</span><span class="p">[</span><span class="n">label_idx</span><span class="p">]</span>

            <span class="c1"># Make all-vs-rest batches per class (Bc=attractor, Bk=repellor set)</span>
            <span class="n">Bc</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">Bk</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">p_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">p_y</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Prototypes</span>
            <span class="n">pc</span> <span class="o">=</span> <span class="n">p_x</span><span class="p">[</span><span class="n">p_idx</span><span class="p">]</span>  <span class="c1"># Class proto</span>
            <span class="n">pk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p_x</span><span class="p">[:</span><span class="n">p_idx</span><span class="p">],</span> <span class="n">p_x</span><span class="p">[</span><span class="n">p_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]])</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="c1"># Accumulate loss for instances of class c</span>
            <span class="n">sum_logLc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attractor</span><span class="p">(</span><span class="n">pc</span><span class="p">,</span> <span class="n">pk</span><span class="p">,</span> <span class="n">Bc</span><span class="p">)</span>
            <span class="n">sum_logLk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">repellor</span><span class="p">(</span><span class="n">pc</span><span class="p">,</span> <span class="n">pk</span><span class="p">,</span> <span class="n">Bc</span><span class="p">,</span> <span class="n">Bk</span><span class="p">)</span> <span class="k">if</span> <span class="n">include_repellor</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">Loss_c</span> <span class="o">=</span> <span class="o">-</span><span class="n">sum_logLc</span> <span class="o">-</span> <span class="n">sum_logLk</span>  <span class="c1"># attractor + repellor for class c</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">Loss_c</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">Loss_c</span>  <span class="c1"># Update loss</span>
        <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">bs</span>  <span class="c1"># Make independent batch size</span></div>

<div class="viewcode-block" id="PPPloss.attractor"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.PPPloss.attractor">[docs]</a>    <span class="k">def</span> <span class="nf">attractor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pc</span><span class="p">,</span> <span class="n">pk</span><span class="p">,</span> <span class="n">Bc</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the attractor loss terms for all instances in xc.</span>
<span class="sd">        :param pc: Prototype of the same class c.</span>
<span class="sd">        :param pk: Prototoypes of the other classes.</span>
<span class="sd">        :param Bc: Batch of instances of the same class c.</span>
<span class="sd">        :return: Sum_{i, the part of same class c} log P(c|x_i^c)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">Bc</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">pc</span><span class="p">,</span> <span class="n">pk</span><span class="p">])</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># Incl other-class proto</span>
        <span class="n">pk_idx</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">pk</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># from when starts p_k</span>

        <span class="c1"># Resulting distance columns are per-instance loss terms</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Bc</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">exp_</span><span class="p">()</span>  <span class="c1"># Distance matrix exp terms</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="o">*</span><span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">Bc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Exclude self-product</span>
        <span class="n">Dm</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Masked out products with self</span>

        <span class="n">Lc_n</span><span class="p">,</span> <span class="n">Lk_d</span> <span class="o">=</span> <span class="n">Dm</span><span class="p">[:</span><span class="n">pk_idx</span><span class="p">],</span> <span class="n">Dm</span><span class="p">[</span><span class="n">pk_idx</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Num/denominator</span>
        <span class="n">Pci</span> <span class="o">=</span> <span class="n">Lc_n</span> <span class="o">/</span> <span class="p">(</span><span class="n">Lc_n</span> <span class="o">+</span> <span class="n">Lk_d</span><span class="p">)</span>  <span class="c1"># Get probabilities per instance</span>
        <span class="n">E_Pc</span> <span class="o">=</span> <span class="n">Pci</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">Bc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Expectation over pseudo-prototypes</span>
        <span class="k">return</span> <span class="n">E_Pc</span><span class="o">.</span><span class="n">log_</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># sum over all instances (sum i)</span></div>

<div class="viewcode-block" id="PPPloss.repellor"><a class="viewcode-back" href="../../../../../autoapi/avalanche/training/plugins/#avalanche.training.plugins.cope.PPPloss.repellor">[docs]</a>    <span class="k">def</span> <span class="nf">repellor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pc</span><span class="p">,</span> <span class="n">pk</span><span class="p">,</span> <span class="n">Bc</span><span class="p">,</span> <span class="n">Bk</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the repellor loss terms for all pseudo-prototype instances in Bc.</span>
<span class="sd">        :param pc: Actual prototype of the same class c.</span>
<span class="sd">        :param pk: Prototoypes of the other classes (k).</span>
<span class="sd">        :param Bc: Batch of instances of the same class c. Acting as</span>
<span class="sd">        pseudo-prototypes.</span>
<span class="sd">        :param Bk: Batch of instances of other-than-c classes (k).</span>
<span class="sd">        :return: Sum_{i, part of same class c} Sum_{x_j^k} log 1 - P(c|x_j^k)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">union_ck</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">Bc</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">pc</span><span class="p">,</span> <span class="n">pk</span><span class="p">])</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">pk_idx</span> <span class="o">=</span> <span class="n">union_ck</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">pk</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Distance other-class-k to prototypes (pc/pk) and pseudo-prototype (xc)</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">union_ck</span><span class="p">,</span> <span class="n">Bk</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">exp_</span><span class="p">()</span>

        <span class="n">Lk_d</span> <span class="o">=</span> <span class="n">D</span><span class="p">[</span><span class="n">pk_idx</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Numerator/denominator terms</span>
        <span class="n">Lc_n</span> <span class="o">=</span> <span class="n">D</span><span class="p">[:</span><span class="n">pk_idx</span><span class="p">]</span>
        <span class="n">Pki</span> <span class="o">=</span> <span class="n">Lc_n</span> <span class="o">/</span> <span class="p">(</span><span class="n">Lc_n</span> <span class="o">+</span> <span class="n">Lk_d</span><span class="p">)</span>  <span class="c1"># probability</span>

        <span class="n">E_Pk</span> <span class="o">=</span> <span class="p">(</span><span class="n">Pki</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">Pki</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># Exp. pseudo/prototype</span>
        <span class="n">inv_E_Pk</span> <span class="o">=</span> <span class="n">E_Pk</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">log_</span><span class="p">()</span>  <span class="c1"># log( (1 - Pk))</span>
        <span class="k">return</span> <span class="n">inv_E_Pk</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># Sum over (pseudo-prototypes), and instances</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, ContinualAI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>